\documentclass{article}
\usepackage[utf8]{inputenc}

\title{COL216 A-5 Write-up}
\author{Sayam Sethi 2019CS10399 \\ Mallika Prabhakar 2019CS50440}
\date{April 2021}
\begin{document}

%Me happy. Doing assignment/making reports feel normal compared to tests and even though they are irritating, they feel good anyway. :')

\maketitle
\section{Assumptions}
The following hardware assumptions were made in the design of the \textbf{MIPS Processor}:
\begin{enumerate}
    \item There are \textbf{three ports} for communication with the processor:
        \begin{enumerate}
            \item Two \textbf{output ports} to send the DRAM request to the \textbf{DRAM queue} (explained in detail in the next point) and signify if there is a ``priority load" required by the processor if it is being stalled.
            \item An \textbf{input port} to receive, and accept or reject the result of the DRAM request after delay.
            \item A \textbf{pair of \{address, value\}} for every register which stores the value of the latest DRAM address from which the value is to be loaded from.
            \item The remaining hardware is the same as for a single pipeline MIPS processor.
        \end{enumerate}
    \item The \textbf{Memory Request Manager (MRM)} has the following hardware components and ports:
        \begin{enumerate}
            \item $N$ \textbf{buffer queues} (which is a fixed sized data segment, $size = 32$) for every core which stores the instructions send to the \textbf{MRM}. Detailed hardware structure is explained in the next section. A \textbf{counter} is also used to keep a track of the number of elements present in the segment.
            \item A \textbf{sw-lw forwarding} register file which stores the latest value of \textbf{\{issue clock cycle, value\}} for the address(es) which are currently present in the \textbf{buffer queue}.
            \item Two \textbf{cyclic priority encoders} which helps decide the core whose instruction is to be processed next.
            \item $2\times N$ \textbf{input ports} which receive the DRAM requests from the cores and the priority signals from the cores.
            \item $N$ \textbf{output ports} which return the DRAM load results to the cores.
            \item Two more \textbf{counters} which keep a track of the number of instructions processed in the current row and cycles remaining for the current request to be processed.
            \item Two \textbf{registers} which store the current core and row whose request is being serviced.
        \end{enumerate}
    \item The \textbf{DRAM architecture} is as follows:
        \begin{enumerate}
            \item It contains a \textbf{2D square array} of $1024$ rows with each row having $1024$ bytes ($256$ words). This memory segment is divided into $N$ blocks to separate the memory locations accessible by the cores.
            \item It contains another storage location called the \textbf{row buffer} which is used to store the current memory retrieval row.
        \end{enumerate}
\end{enumerate}
Note: $N$ is taken to be $16$ in our implementation, however the value can be changed to any number that is a factor of $1024$.


% @TODO: change implementation totally
\section{Implementation}

% @TODO: add the implementation's time complexity as well
\subsection{Algorithm}
The idea behind our implementation is to ensure that all cores are serviced as soon as possible and no core is left waiting for too long. The \textbf{MRM} has separate buffers for every core, which has a maximum size of $32$ requests each. The buffer is implemented as an \textit{unordered map} of \textit{queue} which helps service the requests sequentially for every row.\par
When the requests are sent to the \textbf{MRM} for the first time (or after the \textbf{MRM} was emptied), it selects the first core which has a request that has been sent to the buffer. In the subsequent selections, it selects requests from the same row (and hence the same core)

\subsection{Hardware Perspective}


\section{Strengths and Weaknesses}

% @TODO: change both the sections completely

\subsection{Strengths}
The reordering of instructions is decided in such a way that it reduces the number of times the row buffer is written back and updated with a new buffer as much as possible.\par
The design choice implements reordering (and skipping) of DRAM instructions with the least amount of additional data storage required. The heaviest part of the algorithm is the selection of the next instruction, which can happen in the same clock cycle in which a previous instruction is completed.\par
The skipping of instructions helps in avoiding a lot of redundant loads which reduce the number of cycles taken to execute the code by a lot. Forwarding of instructions ensures that if the user is working with a particular location in the memory, the load time is greatly reduced.\par
The maximum size of the \textbf{queue} is set as $32$ since this allows for maximum data capacity without having the need to make the DRAM access blocking (on reaching maximum size). Any larger would lead to unused memory for most of the times and any smaller would lead to frequent blocking.

\subsection{Weaknesses}
The design is kept as simple as possible to reduce the hardware complexity of the processor. This led to the pushing of every store instruction to the \textbf{queue} and the same leads to some redundant store operations. Removing this redundancy would lead to using a data structure whose size would be comparable to the data memory, i.e.\ $2^{20}$ bytes, hence the inefficiency of $sw$.\par
The retrieval time for the next most optimal instruction has been kept as small as possible which has lead to the chance of selection of a slightly sub-optimal instruction at times (this is governed by the hash values of the row/column). To enhance the quality of selection, order of the arrival of instructions would need to be maintained which would lead to a slower selection (spanning over multiple clock cycles) and would require memory comparable to the size of the instructions (which, in the worst case can be equal to the size of the data memory, i.e.\ $2^{20}$ bytes).



\section{Testing Strategy}
% @TODO: Describe the folders broadly and change testing cases section
% @TODO: add more tests

Testing was carried keeping the following cases in mind:
\begin{enumerate}
    \item Queuing up of DRAM instructions while safe instructions are executed in parallel.
    \item Queuing up of instructions along with an unsafe instruction requiring a pending instruction to be completed.
    \item Multiple load/store instructions involving the same register so that the queue handling is tested effectively.
    \item Tested on large cases which were give for Assignment 3 and Minor which had some other combinations of cases that were not handled above.
\end{enumerate}
\subsection*{Test Cases:}
\begin{enumerate}
%see if cores change while running
    \item \textbf{Test1 -} initial testcase to test multicore functionality
%check smooth row changes
    \item \textbf{Test2 -} testcase to test execution when row changes are needed (no dependent instructions)
%
    \item \textbf{Test3 -} tests execution when instructions are skipped + stopping a single core on error
% random cases involving dependencies in all cores
    \item \textbf{OnlyStores -} the name is suggestive % stink eye
%
    \item \textbf{Prep -} Each core respectively: dependent loads, no DRAM, forwarding
%
    \item \textbf{Unsafes -} Unsafe instructions in all cores (forwarding happens in 2 out of 4 cores).
%
    \item \textbf{Test7 -} wut
%
    \item \textbf{Test8 -} wut
%
    \item \textbf{Test9 -} wut
%
    \item \textbf{Test9 -} wut
\end{enumerate}




\end{document}